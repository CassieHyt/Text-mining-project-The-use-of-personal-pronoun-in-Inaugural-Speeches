date_pattern2 <- "[a-zA-z]+"
tx_words2 <- grep(tx_words, pattern = date_pattern2, value=T)
tx_log <- grepl(tx_words2, pattern = date_pattern2)
matches <- gregexpr(pattern = date_pattern2, text = tx_words2[tx_log])
tx_words <- unlist(regmatches(tx_words2[tx_log], matches))
tx_words <- unlist(rm_stopwords(tx_words))
mat<-NULL
table<-table(tx_words)
word<-names(table)
n<-unname(table)
matname<-paste(inaug.list$File[i],inaug.list$Term[i])
mat<-cbind(rep(matname,nrow(n)),word,n)
mat1<-rbind(mat1,mat)
}
colnames(mat1)<-c("name","word","n")
matsort<-mat1[order(as.numeric(mat1[,3]),decreasing = T),]
#head(matsort)
#personal pronoun
first1<-c("I","me","mine","my")
first2<-c("we","our","ours","us")
second<-c("you","your","yours")
third<-c("he","she","it","him","her","his","hers","they","them","their")
personal<-list(first1,first2,second,third)
pp_mat<-matrix(nrow = nrow(inaug.list),ncol = 4)
for(i in seq(nrow(inaug.list))) {
test<-matsort[matsort[,"name"]==paste(inaug.list$File[i],inaug.list$Term[i]),"word"]
pp_mat[i,]<-find_personal_pronoun(test)
}
ppname<-NULL
for(i in seq(nrow(inaug.list))) {
ppname[i] <- paste(inaug.list$File[i], inaug.list$Term[i]) }
rownames(pp_mat)<-ppname
colnames(pp_mat)<-c("first1","first2","second","third")
head(pp_mat)
pp_mat1<-pp_mat
rownames(pp_mat1)<-seq(1789,2017,4)
pp_mat2<-melt(pp_mat1)
pp_mat3<-melt(pp_mat)
new1<-mat2mat(pp_mat)
a<-ggplot(data.frame(personal_pronoun=new1[,"type"],new1[,"name"],new1[,"prop"]), aes(x=factor(new1[,"name"], levels=unique(new1[,"name"])),y=new1[,"prop"], colour=personal_pronoun,group=personal_pronoun))+ geom_line(size=2) + theme(axis.text.x = element_blank()) + xlab("time with different presidents") + ylab("proportion")
pp_dat<-data.frame(year=pp_mat2$Var1,proportion=pp_mat2$value,personal_pronoun=pp_mat2$Var2)
b<-ggplot(pp_dat, aes(x = year, y = proportion, fill = personal_pronoun)) +
geom_area() +
scale_fill_brewer(palette = "Blues", breaks = rev(c("third","second","first2","first1")))
pp_dat<-data.frame(president=pp_mat3$Var1,proportion=pp_mat2$value,personal_pronoun=pp_mat2$Var2)
c<-ggplot(pp_dat,aes(president,proportion,fill=personal_pronoun))+geom_bar(stat="identity",position="stack")+ggtitle("")+guides(fill=guide_legend(title=NULL))+
scale_fill_brewer(palette = "Blues")+ theme(axis.text.x = element_blank()) + xlab("time with different presidents")
grid.arrange(b,c,nrow=2)
grid.arrange(a,nrow=1)
#different term
avg<-apply(pp_mat,2,mean)
list<-term_sep()
avg_term1<-apply(pp_mat[list[[1]],],2,mean)
avg_term2<-apply(pp_mat[list[[2]],],2,mean)
df1<-data.frame(avg,avg_term1,avg_term2)
dat<-t(df1)
mydat<-melt(dat)
#mydat
mydat<-data.frame(term = mydat$Var1,personal_pronoun = mydat$Var2,proportion=mydat$value)
ggplot(mydat,aes(term,proportion,fill=personal_pronoun))+geom_bar(stat="identity",position="stack")+ggtitle("")+theme(axis.ticks.length=unit(0.5,'cm'))+guides(fill=guide_legend(title=NULL))+
scale_fill_brewer(palette = "Blues")
#different party
new_inaug.list<-cbind(inaug.list,pp_mat)
first1<-tapply(new_inaug.list$first1,new_inaug.list$Party,mean)
first2<-tapply(new_inaug.list$first2,new_inaug.list$Party,mean)
second<-tapply(new_inaug.list$second,new_inaug.list$Party,mean)
third<-tapply(new_inaug.list$third,new_inaug.list$Party,mean)
#head(new_inaug.list)
#aggregate(new_inaug.list,)
dat<-rbind(unname(first1),unname(first2),unname(second),unname(third))
colnames(dat)<-names(first1)
rownames(dat)<-c("first1","first2","second","third")
mydat<-melt(dat)
mydat<-data.frame(personal_pronoun = mydat$Var1, party = mydat$Var2,proportion=mydat$value)
mydat
ggplot(mydat,aes(party,proportion,fill=personal_pronoun))+geom_bar(stat="identity",position="stack")+ggtitle("")+theme(axis.ticks.length=unit(0.5,'cm'))+guides(fill=guide_legend(title=NULL))+
scale_fill_brewer(palette = "Blues")+ theme(axis.text.x = element_text(angle = 15, hjust = 0.5, vjust = 0.5))
data1<-pp_mat[order(pp_mat[,1],decreasing = T),][1:10,]
data2<-pp_mat[order(pp_mat[,2],decreasing = T),][1:10,]
data3<-pp_mat[order(pp_mat[,3],decreasing = T),][1:10,]
data4<-pp_mat[order(pp_mat[,4],decreasing = T),][1:10,]
new1<-mat2mat(data1)
new2<-mat2mat(data2)
new3<-mat2mat(data3)
new4<-mat2mat(data4)
par(mfrow=c(2,2))
ggplot(data.frame(new1[,"type"],new1[,"name"],new1[,"prop"]), aes(x=factor(new1[,"name"], levels=unique(new1[,"name"])), y=new1[,"prop"], colour=new1[,"type"],group=new1[,"type"]))+ geom_line(size=2) + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) + xlab("Top 10 using first1 personal pronoun") + ylab("proportion")
ggplot(data.frame(new2[,"type"],new2[,"name"],new2[,"prop"]), aes(x=factor(new2[,"name"], levels=unique(new2[,"name"])), y=new2[,"prop"], colour=new2[,"type"],group=new2[,"type"])) + geom_line(size=2) + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) + xlab("Top 10 using first2 personal pronoun") + ylab("proportion")
ggplot(data.frame(new3[,"type"],new3[,"name"],new3[,"prop"]), aes(x=factor(new3[,"name"], levels=unique(new3[,"name"])), y=new3[,"prop"], colour=new3[,"type"],group=new3[,"type"])) + geom_line(size=2) + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) + xlab("Top 10 using second personal pronoun") + ylab("proportion")
ggplot(data.frame(new4[,"type"],new4[,"name"],new4[,"prop"]), aes(x=factor(new4[,"name"], levels=unique(new4[,"name"])), y=new4[,"prop"], colour=new3[,"type"],group=new4[,"type"])) + geom_line(size=2) + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) + xlab("Top 10 using third personal pronoun") + ylab("proportion")
data(positive.words)
data(negative.words)
sentiment_analy<-function(words)
{
score<-NULL
# compare words to the dictionaries of positive & negative terms
positive.matches = match(words, positive.words)
negative.matches = match(words, negative.words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
positive_matches = !is.na(positive.matches)
negative_matches = !is.na(negative.matches)
score = sum(positive_matches) - sum(negative_matches)
return(score)
}
senti_vec<-NULL
for(i in seq(nrow(inaug.list))) {
test<-matsort[matsort[,"name"]==paste(inaug.list$File[i],inaug.list$Term[i]),"word"]
senti_vec[i]<-sentiment_analy(test)
}
svname<-NULL
for(i in seq(nrow(inaug.list))) {
svname[i] <- paste(inaug.list$File[i], inaug.list$Term[i]) }
senti_vec
#sentiment vs person
senti_mat<-cbind(ppname,senti_vec)
n1<-match(rownames(data1),ppname)
n2<-match(rownames(data2),ppname)
n3<-match(rownames(data3),ppname)
n4<-match(rownames(data4),ppname)
senti_mat2<-cbind(senti_mat[n1,2],rep("first1",10))
senti_mat2<-rbind( senti_mat2 , cbind(senti_mat[n2,2],rep("first2",10)) )
senti_mat2<-rbind( senti_mat2 , cbind(senti_mat[n3,2],rep("second",10)) )
senti_mat2<-rbind( senti_mat2 , cbind(senti_mat[n4,2],rep("third",10)) )
colnames(senti_mat2)<-c("sentimental_scores","personal_pron")
dat<-data.frame(senti_mat2)
p <- ggplot(dat, aes(personal_pron, as.numeric(sentimental_scores)))
p + geom_boxplot()
#avg time vs person
avg_mat<-matrix(nrow = nrow(inaug.list),ncol = 2)
avg_mat[,1]<-ppname
for(i in seq(nrow(inaug.list))) {
test<-matsort[matsort[,"name"]==paste(inaug.list$File[i],inaug.list$Term[i]),]
avg_mat[i,2]<-sum(as.numeric(test[,3]))/nrow(test)
}
senti_mat3<-cbind(avg_mat[n1,2],rep("first1",10))
senti_mat3<-rbind( senti_mat3 , cbind(avg_mat[n2,2],rep("first2",10)) )
senti_mat3<-rbind( senti_mat3 , cbind(avg_mat[n3,2],rep("second",10)) )
senti_mat3<-rbind( senti_mat3 , cbind(avg_mat[n4,2],rep("third",10)) )
colnames(senti_mat3)<-c("word_avg_time","personal_pron")
dat<-data.frame(senti_mat3)
p <- ggplot(dat, aes(personal_pron, as.numeric(word_avg_time)))
p + geom_boxplot()
inaug.list=read.csv("../data/InaugurationInfo.csv", stringsAsFactors = FALSE)
inaug.data=read.table("../data/InauguationDates.txt", stringsAsFactors = FALSE,blank.lines.skip=F,sep= "\t")
first1<-c("I","me","mine","my")
first2<-c("we","our","ours","us")
second<-c("you","your","yours")
third<-c("he","she","it","him","her","his","hers","they","them","their")
personal<-list(first1,first2,second,third)
speech.list=read.csv("../data/InaugurationInfo.csv", stringsAsFactors = FALSE)
speech.list$type=c(rep("inaug", nrow(speech.list)))
speech.list$fulltext=NA
sentence.list=NULL
order(pp_mat[,1],decreasing = T)
order(pp_mat[,2],decreasing = T)
order(pp_mat[,3],decreasing = T)
order(pp_mat[,4],decreasing = T)
data1<-pp_mat[order(pp_mat[,1],decreasing = T),][1:10,]
data2<-pp_mat[order(pp_mat[,2],decreasing = T),][1:10,]
data3<-pp_mat[order(pp_mat[,3],decreasing = T),][1:10,]
data4<-pp_mat[order(pp_mat[,4],decreasing = T),][1:10,]
new1<-mat2mat(data1)
new2<-mat2mat(data2)
new3<-mat2mat(data3)
new4<-mat2mat(data4)
par(mfrow=c(2,2))
ggplot(data.frame(new1[,"type"],new1[,"name"],new1[,"prop"]), aes(x=factor(new1[,"name"], levels=unique(new1[,"name"])), y=new1[,"prop"], colour=new1[,"type"],group=new1[,"type"]))+ geom_line(size=2) + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) + xlab("Top 10 using first1 personal pronoun") + ylab("proportion")
ggplot(data.frame(new2[,"type"],new2[,"name"],new2[,"prop"]), aes(x=factor(new2[,"name"], levels=unique(new2[,"name"])), y=new2[,"prop"], colour=new2[,"type"],group=new2[,"type"])) + geom_line(size=2) + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) + xlab("Top 10 using first2 personal pronoun") + ylab("proportion")
ggplot(data.frame(new3[,"type"],new3[,"name"],new3[,"prop"]), aes(x=factor(new3[,"name"], levels=unique(new3[,"name"])), y=new3[,"prop"], colour=new3[,"type"],group=new3[,"type"])) + geom_line(size=2) + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) + xlab("Top 10 using second personal pronoun") + ylab("proportion")
ggplot(data.frame(new4[,"type"],new4[,"name"],new4[,"prop"]), aes(x=factor(new4[,"name"], levels=unique(new4[,"name"])), y=new4[,"prop"], colour=new3[,"type"],group=new4[,"type"])) + geom_line(size=2) + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) + xlab("Top 10 using third personal pronoun") + ylab("proportion")
senten_mat2<-melt(senten_mat(28))
sen_dat<-data.frame(sentence.number=senten_mat2$Var1,times=senten_mat2$value,personal_pronoun=senten_mat2$Var2)
senti_mat<-count_emo(28)[,c(1,2,4,5,7,8)]
rownames(senti_mat)<-seq(1,nrow(senti_mat))
senti_mat2<-melt(senti_mat)
senti_dat<-data.frame(sentence_number=senti_mat2$Var1,score=senti_mat2$value,sentiment=senti_mat2$Var2)
par(mfrow=c(1,2))
a1<-ggplot(sen_dat,aes(sentence.number,times,fill=personal_pronoun))+geom_bar(stat="identity",position="stack")+ggtitle("")+guides(fill=guide_legend(title=NULL))+
scale_fill_brewer(palette = "Blues")+ xlab("")
#b1<-ggplot(senti_dat, aes(x = sentence_number, y = score, fill = sentiment)) +
#  geom_area()
# + scale_fill_brewer(palette = "RdBu", breaks = rev(c(factor(sentiment))))
b1<-ggplot(senti_dat,aes(x = sentence_number, y = score, fill = sentiment))+geom_bar(stat="identity",position="stack")+ggtitle("")+guides(fill=guide_legend(title=NULL))
grid.arrange(a1,b1,nrow=2)
senten_mat2<-melt(senten_mat(2))
sen_dat<-data.frame(sentence.number=senten_mat2$Var1,times=senten_mat2$value,personal_pronoun=senten_mat2$Var2)
senti_mat<-count_emo(2)[,c(1,2,4,5,7,8)]
rownames(senti_mat)<-seq(1,nrow(senti_mat))
senti_mat2<-melt(senti_mat)
senti_dat<-data.frame(sentence_number=senti_mat2$Var1,score=senti_mat2$value,sentiment=senti_mat2$Var2)
par(mfrow=c(1,2))
a1<-ggplot(sen_dat,aes(sentence.number,times,fill=personal_pronoun))+geom_bar(stat="identity",position="stack")+ggtitle("")+guides(fill=guide_legend(title=NULL))+
scale_fill_brewer(palette = "Blues")+ xlab("")
#b1<-ggplot(senti_dat, aes(x = sentence_number, y = score, fill = sentiment)) +
#  geom_area()
# + scale_fill_brewer(palette = "RdBu", breaks = rev(c(factor(sentiment))))
b1<-ggplot(senti_dat,aes(x = sentence_number, y = score, fill = sentiment))+geom_bar(stat="identity",position="stack")+ggtitle("")+guides(fill=guide_legend(title=NULL))
grid.arrange(a1,b1,nrow=2)
senten_mat<-function(i)#ith president
{
sentence<-NULL
filename <- paste0("../data/InauguralSpeeches/inaug", inaug.list$File[i], "-", inaug.list$Term[i], ".txt")
tx <- readLines(filename,warn=F)
sentence<-sent_detect(tx,endmarks = c("?", ".", "!", "|",";"))
sen_mat<-matrix(nrow = length(sentence),ncol = 4)
colnames(sen_mat)<-c("first1","first2","second","third")
rownames(sen_mat)<-seq(1:length(sentence))
for (j in 1:4)
{
for (k in 1:length(sentence))
{
tx<-paste(sentence[[k]], collapse = " ")
tx_words <- strsplit(sentence[[k]], split = " ")[[1]]
date_pattern2 <- "[a-zA-z]+"
tx_words2 <- grep(tx_words, pattern = date_pattern2, value=T)
tx_log <- grepl(tx_words2, pattern = date_pattern2)
matches <- gregexpr(pattern = date_pattern2, text = tx_words2[tx_log])
tx_words <- unlist(regmatches(tx_words2[tx_log], matches))
words2<-personal[[j]]
matches = match(tx_words, words2)
matches = !is.na(matches)
sen_mat[k,j] = sum(matches)
}}
return(sen_mat)
}
senten_mat(58)
senten_mat(58)
i<-2
filename <- paste0("../data/InauguralSpeeches/inaug", speech.list$File[i], "-",speech.list$Term[i], ".txt")
speech.list$fulltext[i] <- readLines(filename,warn=F)
sentences=sent_detect(speech.list$fulltext[i],endmarks = c("?", ".", "!", "|",";"))
i<-2
filename <- paste0("../data/InauguralSpeeches/inaug", speech.list$File[i], "-",speech.list$Term[i], ".txt")
speech.list$fulltext[i] <- readLines(filename,warn=F)
sentences=sent_detect(speech.list$fulltext[i],endmarks = c("?", ".", "!", "|",";"))
sentences
i<-1
j<-1
word<-sentences[i]
words2<-personal_pro[[j]]
matches = match(words, words2)
first1<-c("I","me","mine","my")
first2<-c("we","our","ours","us")
second<-c("you","your","yours")
third<-c("he","she","it","him","her","his","hers","they","them","their")
personal<-list(first1,first2,second,third)
word<-sentences[i]
words2<-personal_pro[[j]]
matches = match(words, words2)
personal_pro=personal
word<-sentences[i]
words2<-personal_pro[[j]]
matches = match(words, words2)
word
words2
k<-1
tx<-paste(sentence[[k]], collapse = " ")
tx_words <- strsplit(sentence[[k]], split = " ")[[1]]
date_pattern2 <- "[a-zA-z]+"
tx_words2 <- grep(tx_words, pattern = date_pattern2, value=T)
tx_log <- grepl(tx_words2, pattern = date_pattern2)
matches <- gregexpr(pattern = date_pattern2, text = tx_words2[tx_log])
tx_words <- unlist(regmatches(tx_words2[tx_log], matches))
words2<-personal_pro[[j]]
matches = match(tx_words, words2)
matches
tx
sentence[[k]]
tx<-paste(sentences[[k]], collapse = " ")
tx_words <- strsplit(sentence[[k]], split = " ")[[1]]
date_pattern2 <- "[a-zA-z]+"
tx_words2 <- grep(tx_words, pattern = date_pattern2, value=T)
tx_log <- grepl(tx_words2, pattern = date_pattern2)
matches <- gregexpr(pattern = date_pattern2, text = tx_words2[tx_log])
tx_words <- unlist(regmatches(tx_words2[tx_log], matches))
words2<-personal_pro[[j]]
matches = match(tx_words, words2)
tx<-paste(sentences[[k]], collapse = " ")
tx_words <- strsplit(sentences[[k]], split = " ")[[1]]
date_pattern2 <- "[a-zA-z]+"
tx_words2 <- grep(tx_words, pattern = date_pattern2, value=T)
tx_log <- grepl(tx_words2, pattern = date_pattern2)
matches <- gregexpr(pattern = date_pattern2, text = tx_words2[tx_log])
tx_words <- unlist(regmatches(tx_words2[tx_log], matches))
words2<-personal_pro[[j]]
matches = match(tx_words, words2)
matches
tx_words
print("\fonta")
print("$2_2$")
print("\$2_2\$")
print("\$2_2\$")
print("$2_2$")
$2_2$
find_conjoint<-function(i0,i,j,personal_pro=personal)#i0th president,ith sentence,jth kind of personal pronoun
find(2,1)
find(2,1)
find_sen<-function(i,j,personal_pro=personal)#ith president,jth sentence
{
filename <- paste0("../data/InauguralSpeeches/inaug", speech.list$File[i0], "-",speech.list$Term[i0], ".txt")
speech.list$fulltext[i0] <- readLines(filename,warn=F)
sentences=sent_detect(speech.list$fulltext[i0],endmarks = c("?", ".", "!", "|",";"))
return(sentences[j])
}
find_sen(2,1)
find_sen(2,1)
find_sen<-function(i,j,personal_pro=personal)#ith president,jth sentence
{
filename <- paste0("../data/InauguralSpeeches/inaug", speech.list$File[i], "-",speech.list$Term[i], ".txt")
speech.list$fulltext[i] <- readLines(filename,warn=F)
sentences=sent_detect(speech.list$fulltext[i],endmarks = c("?", ".", "!", "|",";"))
return(sentences[j])
}
find_sen(2,1)
a1<-ggplot(sen_dat,aes(sentence.number,times,fill=personal_pronoun))+geom_bar(stat="identity",position="stack")+ggtitle("")+guides(fill=guide_legend(title=NULL))+
scale_fill_brewer(palette = "Blues")+ xlab("")
#b1<-ggplot(senti_dat, aes(x = sentence_number, y = score, fill = sentiment)) +
#  geom_area()
# + scale_fill_brewer(palette = "RdBu", breaks = rev(c(factor(sentiment))))
b1<-ggplot(senti_dat,aes(x = sentence_number, y = score, fill = sentiment))+geom_bar(stat="identity",position="stack")+ggtitle("")+guides(fill=guide_legend(title=NULL))
grid.arrange(a1,b1,nrow=2)
library(shiny)
library(ggplot2)
shinyServer<-function(input, output) {
output$plot <- reactivePlot(function() {
p <- ggplot(dataset, aes_string(x=input$x, y=input$y))+geom_point()
if (input$color != 'None')
p <- p+aes_string(color=input$color)+theme(legend.position="top")
if (input$smooth)
p <- p+geom_smooth()+theme(legend.position="top")
print(p)
}, height=400)
}
dataset<-iris
shinyUI(
pageWithSidebar(
headerPanel("flower"),
sidebarPanel(
selectInput('x', 'X', names(dataset)),
selectInput('y', 'Y', names(dataset)[2]),
selectInput('color', 'Color', c('None', names(dataset))),
checkboxInput('smooth', 'Smooth')
),
mainPanel(plotOutput('plot'))
))
library(shiny)
runApp("d:/test/shinyapp")
library(shiny)
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speech 1',
speeches,
selected=speeches[5])),
column(4, selectInput('speech2', 'Speech 2', speeches,
selected=speeches[9])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
# Combine the selected variables into a new data frame
selectedData <- reactive({
list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],
dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],
dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],
dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])
})
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(selectedData()$dtm.term1,
selectedData()$dtm.count1,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech1)
wordcloud(selectedData()$dtm.term2,
selectedData()$dtm.count2,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech2)
})
},
options = list(height = 600)
)
library(shiny)
library(ggplot2)
shinyApp({
dataset<-iris
ui =
shinyUI(
pageWithSidebar(
headerPanel("flower"),
sidebarPanel(
selectInput('x', 'X', names(dataset)),
selectInput('y', 'Y', names(dataset)[2]),
selectInput('color', 'Color', c('None', names(dataset))),
checkboxInput('smooth', 'Smooth')
),
mainPanel(plotOutput('plot'))
))
,
library(devtools)
install_github("XD-DENG/ECharts2Shiny")
library(recharts)
echartr(iris, Sepal.Length, Sepal.Width, series = Species)
??echarte
??echartr
require(devtools)
install_github('recharts', 'taiyun')
library(recharts)
echartr(iris, Sepal.Length, Sepal.Width, series = Species)
library(recharts)
mapData <- data.frame(province=c("上海", "江苏", "广东", "黑龙江"),
val1=c(100, 200, 300, 500), val2=c(200,300,400,200), val3=c(1,2,3,5), stringsAsFactors=F)
eMap(mapData, namevar=~province, datavar = ~val1+val2)
df2 = data.frame(
saleNum=c(10,20,30,40,50,60,70,15,25,35,45,55,65,75,25,35,45,55,65,75,85),
seller=c(rep("小黄",7), rep("小红",7), rep("小白",7)),
weekDay = c(rep(c("周一","周二","周三","周四","周五","周六","周日"),3))
)
eBar(dat= df2, xvar=~weekDay, yvar=~saleNum, series=~seller)
iris$Species <- as.character(iris$Species)
iris$Species[1:20] ="小红帽"
ePoints(iris, ~Sepal.Length, ~Sepal.Width, series = ~Species)
packages.used=c("RColorBrewer","qdap","ggplot2","reshape2","syuzhet","tm","qdap","reshape2","gridExtra","ggplot2","wordcloud","dplyr","tidytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# library packages
library("RColorBrewer")
library("qdap")
library("ggplot2")
library("reshape2")
library("syuzhet")
library("tm")
library("qdap")
library("reshape2")
library("gridExtra")
library("ggplot2")
library("wordcloud")
library("dplyr")
library("tidytext")
require(devtools)
install_github('recharts', 'taiyun')
source("../lib/customized_function.R")
require(devtools)
install_github('recharts', 'taiyun')
source("../lib/ui.R")
source("../lib/server.R")
i<-1
j<-1
filename <- paste0("../data/InauguralSpeeches/inaug", speech.list$File[i], "-",speech.list$Term[i], ".txt")
speech.list$fulltext[i] <- readLines(filename,warn=F)
sentences=sent_detect(speech.list$fulltext[i],endmarks = c("?", ".", "!", "|",";"))
print(paste("Sentence in",Sentence inspeech.list$File[i],"InauguralSpeeches for the",speech.list$Term[i],"term:",sentences[j])
filename <- paste0("../data/InauguralSpeeches/inaug", speech.list$File[i], "-",speech.list$Term[i], ".txt")
speech.list$fulltext[i] <- readLines(filename,warn=F)
sentences=sent_detect(speech.list$fulltext[i],endmarks = c("?", ".", "!", "|",";"))
print("Sentence in",Sentence inspeech.list$File[i],"InauguralSpeeches for the",speech.list$Term[i],"term:",sentences[j])
find_sen(2,1)
packages.used=c("RColorBrewer","qdap","ggplot2","reshape2","syuzhet","tm","qdap","reshape2","gridExtra","ggplot2","wordcloud","dplyr","tidytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# library packages
library("RColorBrewer")
library("qdap")
library("ggplot2")
library("reshape2")
library("syuzhet")
library("tm")
library("qdap")
library("reshape2")
library("gridExtra")
library("ggplot2")
library("wordcloud")
library("dplyr")
library("tidytext")
require(devtools)
install_github('recharts', 'taiyun')
source("../lib/customized_function.R")
find_sen(2,1)
find_sen(2,1)
senten_mat2<-melt(senten_mat(39))
setwd("~/ads/Spr2017-Proj1-CassieHyt/lib")
unlink('proj1_final_report_cache', recursive = TRUE)
